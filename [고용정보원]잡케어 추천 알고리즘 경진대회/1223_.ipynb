{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# EDA\n",
    "import klib\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import gc\n",
    "import random\n",
    "import re\n",
    "from typing import List ,Dict, Tuple\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# 한글 폰트 설정\n",
    "from statsmodels import robust\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import platform\n",
    "your_os = platform.system()\n",
    "if your_os == 'Linux':\n",
    "    rc('font', family='NanumGothic')\n",
    "elif your_os == 'Windows':\n",
    "    ttf = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=ttf).get_name()\n",
    "    rc('font', family=font_name)\n",
    "elif your_os == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "SUBMIT_PATH = \"submission/\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 35), (46404, 34))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{DATA_PATH}train.csv')\n",
    "test = pd.read_csv(f'{DATA_PATH}test.csv')\n",
    "\n",
    "d_code = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv').iloc[:, :-1]\n",
    "h_code = pd.read_csv(f'{DATA_PATH}속성_H_코드.csv')\n",
    "l_code = pd.read_csv(f'{DATA_PATH}속성_L_코드.csv')\n",
    "\n",
    "train.shape , test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing & engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 - 속성코드 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_code(df, d_code, h_code, l_code):\n",
    "    df = df.copy()   \n",
    "\n",
    "    # D Code\n",
    "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    # H Code\n",
    "    df['person_prefer_h_1_u'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    df['person_prefer_h_2_u'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    df['person_prefer_h_3_u'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    df['contents_attribute_h_u'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "\n",
    "    # L Code\n",
    "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
    "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
    "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
    "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_d = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv', index_col=0).iloc[:, :4].T.to_dict()\n",
    "code_h = pd.read_csv(f'{DATA_PATH}속성_H_코드.csv', index_col=0).T.to_dict()\n",
    "code_l = pd.read_csv(f'{DATA_PATH}속성_L_코드.csv', index_col=0).T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_code(train, code_d, code_h, code_l)\n",
    "test = add_code(test, code_d, code_h, code_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 59), (46404, 58))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contents_open_dt 관련 시계열 피처\n",
    "1. 연월일시간 중에 어떤 요소가 중요한가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['contents_open_dt'] = pd.to_datetime(train['contents_open_dt'])\n",
    "test['contents_open_dt'] = pd.to_datetime(test['contents_open_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['contents_open_year'] = train['contents_open_dt'].dt.year\n",
    "train['contents_open_month'] = train['contents_open_dt'].dt.month\n",
    "train['contents_open_day'] = train['contents_open_dt'].dt.day\n",
    "train['contents_open_dow'] = train['contents_open_dt'].dt.dayofweek\n",
    "train['contents_open_hour'] = train['contents_open_dt'].dt.hour\n",
    "\n",
    "#test['contents_open_year'] = test['contents_open_dt'].dt.year\n",
    "test['contents_open_month'] = test['contents_open_dt'].dt.month\n",
    "test['contents_open_day'] = test['contents_open_dt'].dt.day\n",
    "test['contents_open_dow'] = test['contents_open_dt'].dt.dayofweek\n",
    "test['contents_open_hour'] = test['contents_open_dt'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weekend'] = train['contents_open_dow'].apply(lambda x : 1 if x > 4 else 0)\n",
    "test['weekend'] = test['contents_open_dow'].apply(lambda x : 1 if x > 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회원속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.sort_values(by='contents_open_dt').reset_index(drop=True)\n",
    "test2 = test.sort_values(by='contents_open_dt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['누적_컨텐츠접촉'] = train2.groupby('person_rn')['person_rn'].cumcount() + 1\n",
    "test2['누적_컨텐츠접촉'] = test2.groupby('person_rn')['person_rn'].cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['누적_컨텐츠접촉'] = train2.sort_values(by='id').reset_index()['누적_컨텐츠접촉']\n",
    "test['누적_컨텐츠접촉'] = test2.sort_values(by='id').reset_index()['누적_컨텐츠접촉']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회원속성 - 컨텐츠 속성 일치 여부 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_code.columns = [\"attribute_d\", \"attribute_d_d\", \"attribute_d_s\", \"attribute_d_m\", \"attribute_d_l\"]\n",
    "h_code.columns = [\"attribute_h\", \"attribute_h_p\"]\n",
    "l_code.columns = [\"attribute_l\", \"attribute_l_d\", \"attribute_l_s\", \"attribute_l_m\", \"attribute_l_l\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_codes(df:pd.DataFrame,df_code:pd.DataFrame,col:str)->pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df_code = df_code.copy()\n",
    "    df_code = df_code.add_prefix(f\"{col}_\")\n",
    "    df_code.columns.values[0] = col\n",
    "    return pd.merge(df,df_code,how=\"left\", on=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "                    df:pd.DataFrame,is_train:bool = True, cols_merge:List[Tuple[str,pd.DataFrame]] = [], cols_equi:List[Tuple[str,str]]= [] ,\n",
    "                    cols_drop:List[str] = [\"id\", \"person_prefer_f\", \"person_prefer_g\", \"contents_open_dt\"]\n",
    "                    )->Tuple[pd.DataFrame,np.ndarray]:\n",
    "    df = df.copy()\n",
    "\n",
    "    y_data = None\n",
    "    if is_train:\n",
    "        y_data = df[\"target\"].to_numpy()\n",
    "        df = df.drop(columns=\"target\")\n",
    "\n",
    "    for col, df_code in cols_merge:\n",
    "        df = merge_codes(df, df_code, col)\n",
    "\n",
    "    cols = df.select_dtypes(bool).columns.tolist()\n",
    "    df[cols] = df[cols].astype(int)\n",
    "\n",
    "    for col1, col2 in cols_equi:\n",
    "        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2]).astype(int)\n",
    "\n",
    "    df = df.drop(columns=cols_drop)\n",
    "    return (df, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소분류 중분류 대분류 속성코드 merge 컬럼명 및 데이터 프레임 리스트\n",
    "cols_merge = [\n",
    "              (\"person_prefer_d_1\" , d_code),\n",
    "              (\"person_prefer_d_2\" , d_code),\n",
    "              (\"person_prefer_d_3\" , d_code),\n",
    "              (\"contents_attribute_d\" , d_code),\n",
    "              (\"person_prefer_h_1\" , h_code),\n",
    "              (\"person_prefer_h_2\" , h_code),\n",
    "              (\"person_prefer_h_3\" , h_code),\n",
    "              (\"contents_attribute_h\" , h_code),\n",
    "              (\"contents_attribute_l\" , l_code),\n",
    "]\n",
    "\n",
    "# 회원 속성과 콘텐츠 속성의 동일한 코드 여부에 대한 컬럼명 리스트\n",
    "cols_equi = [\n",
    "\n",
    "    (\"contents_attribute_c\", \"person_prefer_c\"),\n",
    "    (\"contents_attribute_e\", \"person_prefer_e\"),\n",
    "\n",
    "    (\"person_prefer_d_2_attribute_d_s\", \"contents_attribute_d_attribute_d_s\"),\n",
    "    (\"person_prefer_d_2_attribute_d_m\", \"contents_attribute_d_attribute_d_m\"),\n",
    "    (\"person_prefer_d_2_attribute_d_l\", \"contents_attribute_d_attribute_d_l\"),\n",
    "    (\"person_prefer_d_3_attribute_d_s\", \"contents_attribute_d_attribute_d_s\"),\n",
    "    (\"person_prefer_d_3_attribute_d_m\", \"contents_attribute_d_attribute_d_m\"),\n",
    "    (\"person_prefer_d_3_attribute_d_l\", \"contents_attribute_d_attribute_d_l\"),\n",
    "\n",
    "    (\"person_prefer_h_1_attribute_h_p\", \"contents_attribute_h_attribute_h_p\"),\n",
    "    (\"person_prefer_h_2_attribute_h_p\", \"contents_attribute_h_attribute_h_p\"),\n",
    "    (\"person_prefer_h_3_attribute_h_p\", \"contents_attribute_h_attribute_h_p\"),\n",
    "\n",
    "]\n",
    "\n",
    "# 학습에 필요없는 컬럼 리스트\n",
    "cols_drop = [\"id\", \"person_prefer_f\", \"person_prefer_g\", \"contents_open_dt\", \"contents_rn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 94), (501951,), (46404, 94))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = preprocess_data(train, cols_merge=cols_merge, cols_equi=cols_equi, cols_drop=cols_drop)\n",
    "x_test, _ = preprocess_data(test, is_train=False, cols_merge=cols_merge, cols_equi=cols_equi, cols_drop=cols_drop)\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 군집분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class KMeansFeaturizer:\n",
    "    \"\"\" 숫자 데이터를 k-평균 클러스터 멤버십으로 변환.\n",
    "\n",
    "    이 변환기는 입력 데이터에 k-평균을 수행해 각 데이터 포인트를 가장 가까운 클러스터의 id로 변환한다.\n",
    "    만약 목표 변수가 주어지면 유사한 데이터 포인트와 함께 grouping되고,\n",
    "    분류 경계에 따르는 클러스터를 생성하기 위해 스케일링되고, k-평균 입력에 포함된다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k = 100, target_scale = 5.0, random_state = None):\n",
    "        self.k = k\n",
    "        self.target_scale = target_scale\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\" 입력 데이터에 k-평균을 수행하고 중심점을 찾는다.\n",
    "        \"\"\"\n",
    "        if y is None: # 목표 변수가 없으면 단순한 k-평균 수행\n",
    "            km_model = KMeans(n_clusters = self.k, n_init = 20, random_state = self.random_state)\n",
    "            km_model.fit(X)\n",
    "            \n",
    "            self.inertia_ = km_model.inertia_\n",
    "            self.km_model = km_model\n",
    "            self.cluster_centers_ = km_model.cluster_centers_\n",
    "            return self\n",
    "\n",
    "        # 목표 변수가 있으면, 적절한 스케일링을 적용하고, 이를 k-평균에 대한 입력 데이터에 포함시킨다.\n",
    "        data_with_target = np.hstack((X, y[:, np.newaxis] * self.target_scale))\n",
    "        # 데이터와 타겟에 대해 사전 학습할 k-평균 모델 구축\n",
    "        km_model_pretrain = KMeans(n_clusters = self.k, n_init = 20, random_state = self.random_state)\n",
    "        km_model_pretrain.fit(data_with_target)\n",
    "\n",
    "        # k평균을 두번째로 실행해 목표 변수 없이 원시 공간에서 클러스터를 얻는다. 사전 학습을 통해 얻은 중심점을 활용해 초기화한다.\n",
    "        # 반복을 통해 클러스터 할당과 중심점 계산을 다시 수행한다.\n",
    "\n",
    "        km_model = KMeans(n_clusters = self.k, init = km_model_pretrain.cluster_centers_[:,:data_with_target.shape[1]-1], n_init = 1, max_iter = 1)\n",
    "\n",
    "        km_model.fit(X)\n",
    "        \n",
    "        self.inertia_ = km_model.inertia_\n",
    "        self.km_model = km_model\n",
    "        self.cluster_centers_ = km_model.cluster_centers_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        \"\"\" 각 입력 데이터 포인트에 대해 가장 가까운 클러스터 ID 산출\n",
    "        \"\"\"\n",
    "        clusters = self.km_model.predict(X)\n",
    "        return clusters[:, np.newaxis]\n",
    "\n",
    "    def fit_transform(self, X, y = None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeansFeaturizer(k=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktr = km.fit_transform(x_train, train[\"target\"])\n",
    "kte = km.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['km'] = ktr.astype(str)\n",
    "x_test['km'] = kte.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    6950\n",
       "36    6813\n",
       "70    6742\n",
       "7     6594\n",
       "74    6536\n",
       "      ... \n",
       "4     3716\n",
       "97    3578\n",
       "22    3569\n",
       "85    3505\n",
       "47    3390\n",
       "Name: km, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['km'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    1488\n",
       "98    1395\n",
       "27    1046\n",
       "49    1039\n",
       "65    1013\n",
       "      ... \n",
       "96      32\n",
       "44      26\n",
       "89      24\n",
       "38      20\n",
       "77      15\n",
       "Name: km, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test['km'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 칼럼 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x_train.columns[x_train.nunique() > 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = set(cat_features) - set(['누적_컨텐츠접촉'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-80784060c951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "n_splits = 5\n",
    "iterations = 3000\n",
    "patience = 50\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6271045\ttest: 0.6342993\tbest: 0.6342993 (0)\ttotal: 3.51s\tremaining: 2h 55m 19s\n",
      "100:\tlearn: 0.6646329\ttest: 0.6842006\tbest: 0.6845411 (96)\ttotal: 8m 22s\tremaining: 4h 10s\n",
      "200:\tlearn: 0.6716887\ttest: 0.6860758\tbest: 0.6860758 (200)\ttotal: 16m 49s\tremaining: 3h 54m 20s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6860763862\n",
      "bestIteration = 201\n",
      "\n",
      "Shrink model to first 202 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6249856\ttest: 0.6300820\tbest: 0.6300820 (0)\ttotal: 3.09s\tremaining: 2h 34m 26s\n",
      "100:\tlearn: 0.6646489\ttest: 0.6856481\tbest: 0.6865826 (96)\ttotal: 11m 49s\tremaining: 5h 42m 45s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6875319318\n",
      "bestIteration = 146\n",
      "\n",
      "Shrink model to first 147 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6228982\ttest: 0.6300020\tbest: 0.6300020 (0)\ttotal: 4.08s\tremaining: 3h 24m 8s\n",
      "100:\tlearn: 0.6640610\ttest: 0.6799150\tbest: 0.6813235 (96)\ttotal: 9m 32s\tremaining: 4h 34m 5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6813235028\n",
      "bestIteration = 96\n",
      "\n",
      "Shrink model to first 97 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6257906\ttest: 0.6271449\tbest: 0.6271449 (0)\ttotal: 4.15s\tremaining: 3h 27m 32s\n",
      "100:\tlearn: 0.6663327\ttest: 0.6796242\tbest: 0.6798930 (91)\ttotal: 9m 40s\tremaining: 4h 37m 31s\n",
      "200:\tlearn: 0.6721270\ttest: 0.6830211\tbest: 0.6830211 (200)\ttotal: 18m 38s\tremaining: 4h 19m 40s\n",
      "300:\tlearn: 0.6757613\ttest: 0.6901416\tbest: 0.6902142 (298)\ttotal: 29m 1s\tremaining: 4h 20m 15s\n",
      "400:\tlearn: 0.6784128\ttest: 0.6922270\tbest: 0.6925714 (378)\ttotal: 38m 47s\tremaining: 4h 11m 28s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6925713859\n",
      "bestIteration = 378\n",
      "\n",
      "Shrink model to first 379 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6385209\ttest: 0.6420230\tbest: 0.6420230 (0)\ttotal: 4.93s\tremaining: 4h 6m 33s\n",
      "100:\tlearn: 0.6666572\ttest: 0.6746614\tbest: 0.6781438 (59)\ttotal: 10m 22s\tremaining: 4h 57m 52s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6781437973\n",
      "bestIteration = 59\n",
      "\n",
      "Shrink model to first 60 iterations.\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "models = []\n",
    "\n",
    "\n",
    "models = []\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "\n",
    "    model = CatBoostClassifier(iterations=iterations, \n",
    "                               random_state=SEED,\n",
    "                               #task_type=\"GPU\",\n",
    "                               eval_metric=\"F1\",\n",
    "                               cat_features=cat_features,\n",
    "                               one_hot_max_size=4)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
    "    if is_holdout:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6860763862259377, 0.6875319318031298, 0.6813235027612716, 0.6925713858713419, 0.6781437972583108]\n",
      "0.6851294007839984\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold값 변경에 따른 검증점수 확인 및 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7061393037465403, 0.7076019314239894, 0.7024781124795965, 0.7090073896544837, 0.7004102555281287]\n",
      "0.7051273985665477\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "scores = []\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "    pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    pred = np.where(pred >= threshold , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(x_test)[:, 1]\n",
    "    pred_list.append(pred)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 산술평균 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean(pred_list, axis=0)\n",
    "pred = np.where(pred >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46399</th>\n",
       "      <td>46399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46400</th>\n",
       "      <td>46400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46401</th>\n",
       "      <td>46401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46402</th>\n",
       "      <td>46402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46403</th>\n",
       "      <td>46403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46404 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  target\n",
       "0          0       0\n",
       "1          1       0\n",
       "2          2       0\n",
       "3          3       0\n",
       "4          4       0\n",
       "...      ...     ...\n",
       "46399  46399       1\n",
       "46400  46400       1\n",
       "46401  46401       1\n",
       "46402  46402       1\n",
       "46403  46403       1\n",
       "\n",
       "[46404 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29254\n",
       "0    17150\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SUBMIT_PATH}jp_1223_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
